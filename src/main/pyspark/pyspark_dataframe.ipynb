{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from  https://www.slideshare.net/databricks/data-wrangling-with-pyspark-for-data-scientists-who-know-pandas-with-andrew-ray\n",
    "path = '/home/yang/derby.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile(path)\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'----------------------------------------------------------------', 1), (u'', 2), (u'user.dir=/home/yang', 1), (u'15', 1), (u'os.version=4.4.0-83-generic', 1), (u'from', 1), (u'19:46:13', 1), (u'with', 1), (u'-', 4), (u'Jul', 1), (u'started', 1), (u\"derby.database.classpath=''\", 1), (u'directory', 1), (u'org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@25510982', 1), (u'Apache', 2), (u'java.runtime.version=1.8.0_111-b14', 1), (u'The', 1), (u'(1704137):', 1), (u'os.arch=amd64', 1), (u'derby.system.home=null', 1), (u'2017:', 1), (u'Corporation', 1), (u'Booting', 1), (u'loader', 1), (u'os.name=Linux', 1), (u'Foundation', 1), (u'file:/opt/spark-2.1.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar', 1), (u'/home/yang/metastore_db', 1), (u'instance', 1), (u'version', 1), (u'Class', 1), (u'10.12.1.1', 1), (u'Database', 1), (u'a816c00e-015d-4612-0884-0000051e0858', 1), (u'Derby', 2), (u'CST', 1), (u'class', 1), (u'Software', 1), (u'on', 1), (u'database', 1), (u'Loader', 1), (u'java.vendor=Oracle', 1), (u'Loaded', 1), (u'Sat', 1)]\n"
     ]
    }
   ],
   "source": [
    "print counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = '/home/yang/toyData/adult_train.csv'\n",
    "data_test = '/home/yang/toyData/adult_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"age\",IntegerType()),\n",
    "    StructField(\"workclass\", StringType()),\n",
    "    StructField(\"fnlwgt\", DoubleType()),\n",
    "    StructField(\"education\", StringType()),\n",
    "    StructField(\"education-num\",IntegerType()),\n",
    "    StructField(\"marital-status\", StringType()),\n",
    "    StructField(\"occupation\", StringType()),\n",
    "    StructField(\"relationship\", StringType()),\n",
    "    StructField(\"race\", StringType()),\n",
    "    StructField(\"sex\", StringType()),\n",
    "    StructField(\"capital-gain\", DoubleType()),\n",
    "    StructField(\"capital-loss\", DoubleType()),\n",
    "    StructField(\"hours-per-week\", DoubleType()),\n",
    "    StructField(\"native-country\", StringType()),\n",
    "    StructField(\"label\", StringType())\n",
    "])\n",
    "     \n",
    "df = spark.read.csv(data_train, header=True, mode=\"DROPMALFORMED\", schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(age,IntegerType,true),StructField(workclass,StringType,true),StructField(fnlwgt,DoubleType,true),StructField(education,StringType,true),StructField(education-num,IntegerType,true),StructField(marital-status,StringType,true),StructField(occupation,StringType,true),StructField(relationship,StringType,true),StructField(race,StringType,true),StructField(sex,StringType,true),StructField(capital-gain,DoubleType,true),StructField(capital-loss,DoubleType,true),StructField(hours-per-week,DoubleType,true),StructField(native-country,StringType,true),StructField(label,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "print df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+----------+-------------+--------------+-------------+--------------+------+-----+------------+------------+--------------+--------------+------+\n",
      "|age| workclass| fnlwgt| education|education-num|marital-status|   occupation|  relationship|  race|  sex|capital-gain|capital-loss|hours-per-week|native-country| label|\n",
      "+---+----------+-------+----------+-------------+--------------+-------------+--------------+------+-----+------------+------------+--------------+--------------+------+\n",
      "| 39| State-gov|77516.0| Bachelors|           13| Never-married| Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
      "+---+----------+-------+----------+-------------+--------------+-------------+--------------+------+-----+------------+------------+--------------+--------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, class: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(1)\n",
    "df.columns\n",
    "df.dtypes\n",
    "df.withColumnRenamed('label','class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, label: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('fnlwgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(age,IntegerType,true),StructField(workclass,StringType,true),StructField(fnlwgt,DoubleType,true),StructField(education,StringType,true),StructField(education-num,IntegerType,true),StructField(marital-status,StringType,true),StructField(occupation,StringType,true),StructField(relationship,StringType,true),StructField(race,StringType,true),StructField(sex,StringType,true),StructField(capital-gain,DoubleType,true),StructField(capital-loss,DoubleType,true),StructField(hours-per-week,DoubleType,true),StructField(native-country,StringType,true),StructField(label,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "poor = df[df.label == '<=50k']\n",
    "print poor.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, label: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, label: string, new : double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.withColumn('new ',F.log(df.age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, label: string, haha: int]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('haha',F.when(df.age>10,1).otherwise(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.join(b,on = 'test')\n",
    "a.join(b,a.ee = b.rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pandas\n",
    "    df  \n",
    "    #[Out]#       data1     data2 key1 key2  \n",
    "    #[Out]# 0  0.439801  1.582861    a  one  \n",
    "    #[Out]# 1 -1.388267 -0.603653    a  two  \n",
    "    #[Out]# 2 -0.514400 -0.826736    b  one  \n",
    "    #[Out]# 3 -1.487224 -0.192404    b  two  \n",
    "    #[Out]# 4  2.169966  0.074715    a  one  \n",
    "    df.groupby('key1').apply(mean)  \n",
    "    #[Out]#          data1     data2  \n",
    "    #[Out]# key1                      \n",
    "    #[Out]# a     0.407166  0.351307  \n",
    "    #[Out]# b    -1.000812 -0.509570  \n",
    "    df.groupby(['key1','key2']).apply(mean)  \n",
    "    #[Out]#               data1     data2  \n",
    "    #[Out]# key1 key2                      \n",
    "    #[Out]# a    one   1.304883  0.828788  \n",
    "    #[Out]#      two  -1.388267 -0.603653  \n",
    "    #[Out]# b    one  -0.514400 -0.826736  \n",
    "    #[Out]#      two  -1.487224 -0.192404 \n",
    "    \n",
    "    pd.pivot_table(df,values ='data1', index='key1', columns='key2',aggfunc = np.sum)  \n",
    "    #[Out]#          data1               data2            \n",
    "    #[Out]# key2       one       two       one       two  \n",
    "    #[Out]# key1                                          \n",
    "    #[Out]# a     1.304883 -1.388267  0.828788 -0.603653  \n",
    "    #[Out]# b    -0.514400 -1.487224 -0.826736 -0.192404  \n",
    "    df.pivot_table(['data1'], index='key1',columns='key2')  \n",
    "    #[Out]#          data1            \n",
    "    #[Out]# key2       one       two  \n",
    "    #[Out]# key1                      \n",
    "    #[Out]# a     1.304883 -1.388267  \n",
    "    #[Out]# b    -0.514400 -1.487224  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "| label|    sex|          avg(age)|\n",
      "+------+-------+------------------+\n",
      "|  >50K|   Male| 44.62578805163614|\n",
      "|  >50K| Female|42.125530110262936|\n",
      "| <=50K| Female|36.210800667222685|\n",
      "| <=50K|   Male|37.147012162876784|\n",
      "+------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df.groupby(['label','sex']).agg({'age':'mean'})\n",
    "a.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+\n",
      "| label|            Female|              Male|\n",
      "+------+------------------+------------------+\n",
      "|  >50K|42.125530110262936| 44.62578805163614|\n",
      "| <=50K|36.210800667222685|37.147012162876784|\n",
      "+------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#index means groupby, columns means pivot\n",
    "b = df.groupby(['label']).pivot('sex').mean('age')\n",
    "b.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+------------------+\n",
      "|summary| label|            Female|              Male|\n",
      "+-------+------+------------------+------------------+\n",
      "|  count|     2|                 2|                 2|\n",
      "|   mean|  null| 39.16816538874281| 40.88640010725646|\n",
      "| stddev|  null| 4.182345298057493| 5.288293145916191|\n",
      "|    min| <=50K|36.210800667222685|37.147012162876784|\n",
      "|    max|  >50K|42.125530110262936| 44.62578805163614|\n",
      "+-------+------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e945821ecbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "a.toPandas().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
